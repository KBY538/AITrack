{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a48ba82b",
   "metadata": {},
   "source": [
    "2021-2 상명대학교 자연어처리 08실습RNN+MNIST\n",
    "2021.11.15.월요일"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bff3bd",
   "metadata": {},
   "source": [
    "* 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d1b8038",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 256 # sms 최대 길이"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74ba27d",
   "metadata": {},
   "source": [
    "# 1. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db19672d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccc09d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['label', 'sms'], dtype='object')\n",
      "(5572, 2)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('sms.tsv', sep='\\t', )\n",
    "print(df.columns)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a8a7437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                sms\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "840aec16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of classes: 2\n",
      "['ham', 'spam']\n",
      "{'ham': 0, 'spam': 1}\n"
     ]
    }
   ],
   "source": [
    "# 클래스 파악\n",
    "classes = sorted(set(df['label']))\n",
    "class_to_idx = {}\n",
    "\n",
    "for i, c in enumerate(classes): # 모든 클래스에 대해\n",
    "    class_to_idx.update({c: i})\n",
    "    \n",
    "nclass = len(classes)\n",
    "\n",
    "print(\"# of classes: %d\" %nclass)\n",
    "print(classes)\n",
    "print(class_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e5118a",
   "metadata": {},
   "source": [
    "# 2. 새로운 DataFrame\n",
    "## 1) 'label, sms'만 남기기\n",
    "## 2) 최대 텍스트 길이 만큼 자르기 # pandas.Series.str.slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03b6d9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame({'label':df['label'], 'sms':df['sms'].str.slice(start=0, stop=max_length)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efc8c6a",
   "metadata": {},
   "source": [
    "## 3) 중복 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85994f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4e95929",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(new_df.drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1ea6393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5169"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90898c54",
   "metadata": {},
   "source": [
    "## 4) 셔플"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8c33f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>K:)all the best:)congrats...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry completely forgot * will pop em round th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>* Am on my way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Fine i miss you very much.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I was just callin to say hi. Take care bruv!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                sms\n",
       "0   ham                       K:)all the best:)congrats...\n",
       "1   ham  Sorry completely forgot * will pop em round th...\n",
       "2   ham                                     * Am on my way\n",
       "3   ham                         Fine i miss you very much.\n",
       "4   ham       I was just callin to say hi. Take care bruv!"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shuffled = new_df.sample(frac=1).reset_index(drop=True)\n",
    "df_shuffled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204b4b30",
   "metadata": {},
   "source": [
    "## 5) train, test 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8ac1a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index for train: 0~4652\n",
      "index for test: 4652~5168\n"
     ]
    }
   ],
   "source": [
    "# train:test = 9:1\n",
    "train_ratio = 0.9\n",
    "\n",
    "# train dataset\n",
    "s, e = 0, int(df_shuffled.shape[0]*train_ratio) # # of rows\n",
    "df_shuffled_label = df_shuffled['label'][s:e]\n",
    "df_shuffled_sms = df_shuffled['sms'][s:e]\n",
    "df_train = pd.DataFrame({'label':df_shuffled_label, 'sms':df_shuffled_sms})\n",
    "print(\"index for train: %d~%d\" %(s, e))\n",
    "\n",
    "#test dataset\n",
    "# train dataset\n",
    "s, e = e, e+int(df_shuffled.shape[0]*(1.0-train_ratio)) # # of rows\n",
    "df_shuffled_label = df_shuffled['label'][s:e]\n",
    "df_shuffled_sms = df_shuffled['sms'][s:e]\n",
    "df_test = pd.DataFrame({'label':df_shuffled_label, 'sms':df_shuffled_sms})\n",
    "print(\"index for test: %d~%d\" %(s, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1cb52b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4652, 2)\n",
      "(516, 2)\n"
     ]
    }
   ],
   "source": [
    "# column 수 확인\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1d0038",
   "metadata": {},
   "source": [
    "## 6) 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09eb8b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('./sms.maxlen.uniq.shuf.train.tsv', header=False, index=False, sep='\\t')\n",
    "df_test.to_csv('./sms.maxlen.uniq.shuf.test.tsv', header=False, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d1a251",
   "metadata": {},
   "source": [
    "* 데이터 로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8bf43e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b140ef19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtext==0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (0.4.0)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchtext==0.4.0) (4.61.1)\n",
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchtext==0.4.0) (1.4.0)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchtext==0.4.0) (1.16.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchtext==0.4.0) (1.19.5)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchtext==0.4.0) (2.26.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->torchtext==0.4.0) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->torchtext==0.4.0) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->torchtext==0.4.0) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->torchtext==0.4.0) (2021.10.8)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext==0.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb90a046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "import numpy as np\n",
    "from data_loader import DataLoader # data_loader.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace75a9b",
   "metadata": {},
   "source": [
    "* RNN+SMS 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7c1558",
   "metadata": {},
   "source": [
    "# 0.1 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0dac9f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aefbb2e",
   "metadata": {},
   "source": [
    "# 0.2 하이퍼파라미터 셋팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7d6eb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "dropout_p = 0.3\n",
    "word_vec_size = 256 # emb_size\n",
    "\n",
    "hidden_size = 512\n",
    "num_layers = 4\n",
    "\n",
    "batch_size = 128\n",
    "num_epochs = 10\n",
    "\n",
    "learning_rate = 0.001 # 교수님께서 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9142a964",
   "metadata": {},
   "source": [
    "input: (batch_size, n, input_size)  \n",
    "hidden: (batch_size, n, hidden_size*2)  \n",
    "out: (batch_size, n, # of classes)  \n",
    "레이어 개수, emb_size  \n",
    "이런 것들 다 hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9dd30ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0002bffe",
   "metadata": {},
   "source": [
    "# 1. SMS train, test dataset 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb80eb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41091fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = DataLoader(\n",
    "        train_fn='./sms.maxlen.uniq.shuf.train.tsv',\n",
    "        batch_size=batch_size,\n",
    "        valid_ratio=.2, # train:val = 8:2\n",
    "        max_vocab=999999, # 크게\n",
    "        min_freq=5, # 문장의 최소 단어 개수\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c44b992",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loaders = DataLoader(\n",
    "        train_fn='./sms.maxlen.uniq.shuf.test.tsv',\n",
    "        batch_size=batch_size,\n",
    "        valid_ratio=.01, # val 안 나눈다. 0은 안 받으므로 0.01\n",
    "        max_vocab=999999,\n",
    "        min_freq=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578f7cd5",
   "metadata": {},
   "source": [
    "# 2. 대략적인 데이터 형태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "277ea5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|train| = 3722 |valid| = 930\n",
      "|vocab| = 1546 |classes| = 2\n"
     ]
    }
   ],
   "source": [
    "print(\"|train| =\", len(loaders.train_loader.dataset),\n",
    "      \"|valid| =\", len(loaders.valid_loader.dataset))\n",
    "\n",
    "vocab_size = len(loaders.text.vocab)\n",
    "num_classes = len(loaders.label.vocab)\n",
    "print(\"|vocab| =\", vocab_size, \"|classes| =\", num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079b657e",
   "metadata": {},
   "source": [
    "# 3. 데이터 로드 함수\n",
    "학습시킬 때 batch_size 단위로 끊어서 로드하기 위함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a29c3c5",
   "metadata": {},
   "source": [
    "# 데이터 로드함수 이해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d71f172b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "한 번에 로드되는 데이터 크기:  128\n",
      "label:  0\n",
      "text:  (15,)\n",
      "label:  0\n",
      "text:  (15,)\n",
      "label:  0\n",
      "text:  (15,)\n",
      "[1]\n",
      "한 번에 로드되는 데이터 크기:  128\n",
      "label:  0\n",
      "text:  (13,)\n",
      "label:  0\n",
      "text:  (13,)\n",
      "label:  0\n",
      "text:  (13,)\n",
      "[2]\n",
      "한 번에 로드되는 데이터 크기:  128\n",
      "label:  0\n",
      "text:  (8,)\n",
      "label:  0\n",
      "text:  (8,)\n",
      "label:  0\n",
      "text:  (8,)\n",
      "[3]\n",
      "한 번에 로드되는 데이터 크기:  128\n",
      "label:  0\n",
      "text:  (30,)\n",
      "label:  0\n",
      "text:  (30,)\n",
      "label:  0\n",
      "text:  (30,)\n"
     ]
    }
   ],
   "source": [
    "n = 3 # 샘플로 그려볼 데이터 개수\n",
    "for i, data in enumerate(loaders.train_loader): # batch_size 만큼\n",
    "    labels = data.label\n",
    "    texts = data.text\n",
    "    \n",
    "    if i>n:\n",
    "        break\n",
    "    print (\"[%d]\" %i)\n",
    "    print(\"한 번에 로드되는 데이터 크기: \", len(labels))\n",
    "    \n",
    "    # 출력\n",
    "    for j in range(n):\n",
    "        label = labels[j].numpy() # tensor -> numpy로 변환\n",
    "        text = texts[j].numpy()\n",
    "        print(\"label: \", label)\n",
    "        print(\"text: \", text.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b749ef",
   "metadata": {},
   "source": [
    "# 4. 모델 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cccc96ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recurrent neural network (many-to-one)\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_size, # vocab_size\n",
    "                 word_vec_size, # word embbeding vector 차원\n",
    "                 hidden_size, # bidirectional LSRM의 hidden state & cell state의 size\n",
    "                 n_classes,\n",
    "                 num_layers=4, # 쌓을 레이어 개수\n",
    "                 dropout_p=0.3\n",
    "                 ):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.word_vec_size = word_vec_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_classes = n_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        \n",
    "        # 입력 차원(vocab_size), 출력 차원(word_vec_size)\n",
    "        self.emb =nn.Embedding(input_size, word_vec_size) # 부터!\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=word_vec_size,\n",
    "                            hidden_size=hidden_size,\n",
    "                            num_layers=num_layers,\n",
    "                            dropout=dropout_p,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True)\n",
    "        self.fc  = nn.Linear(hidden_size*2, num_classes)\n",
    "        # LogSoftmax + NLLLoss instead of Softmax + CrossEntropy\n",
    "        self.activation = nn.LogSoftmax(dim=1) # 마지막 차원에 softmax\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, length)\n",
    "        x = self.emb(x)\n",
    "        \n",
    "        # x: (batch_size, length, word_vec_size)\n",
    "        x, _ = self.lstm(x) # x: output, _: 마지막 time step의 hidden state & cell state\n",
    "        \n",
    "        # x: (batch_size, length, hidden_size*2)\n",
    "        # x[:,-1]: (batch_size, 1, hidden_size*2)\n",
    "        out = self.activation(self.fc(x[:,-1])) # 마지막 time step\n",
    "        # self.fc(x[:,-1]): (batch_size, num_classes)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eeca6625",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(input_size=vocab_size,\n",
    "            word_vec_size=word_vec_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            n_classes=num_classes,\n",
    "            dropout_p=dropout_p).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24f0a202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeAccr(dloader, imodel):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    imodel.eval() # test mode\n",
    "    for i, data in enumerate(dloader): # batch_size만큼\n",
    "        texts = data.text.to(device) # (batch_size, length)\n",
    "        labels = data.label.to(device) # (batch_size, num_classes)\n",
    "        \n",
    "        # Forward prop.\n",
    "        output = imodel(texts) # (batch_size, num_classes)\n",
    "        _, output_index = torch.max(output, 1) # (batch_size, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        \n",
    "        correct += (output_index == labels).sum().float()\n",
    "        # print(\"Accuracy of Test Data: {}\".format(100*correct/total))\n",
    "    \n",
    "    imodel.train()\n",
    "    return (100*correct/total).numpy() # tensor -> numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6f5b7f6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Test Data: 12.37\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Test Data: %.2f\" %ComputeAccr(loaders.valid_loader, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc123bad",
   "metadata": {},
   "source": [
    "# 5. loss, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "697b2619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "#loss_func = nn.CrossEntropyLoss()\n",
    "loss_func = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3831b8e9",
   "metadata": {},
   "source": [
    "# 6. 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "631b4818",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "Epoch[1/10], Step [10/30], Loss: 0.3581, Accr: 87.63\n",
      "[10]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[19]\n",
      "Epoch[1/10], Step [20/30], Loss: 0.2312, Accr: 87.63\n",
      "[20]\n",
      "[21]\n",
      "[22]\n",
      "[23]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[27]\n",
      "[28]\n",
      "[29]\n",
      "Epoch[1/10], Step [30/30], Loss: 0.2016, Accr: 87.63\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "Epoch[2/10], Step [10/30], Loss: 0.0899, Accr: 87.63\n",
      "[10]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[19]\n",
      "Epoch[2/10], Step [20/30], Loss: 0.8529, Accr: 87.63\n",
      "[20]\n",
      "[21]\n",
      "[22]\n",
      "[23]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[27]\n",
      "[28]\n",
      "[29]\n",
      "Epoch[2/10], Step [30/30], Loss: 0.7128, Accr: 87.63\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "Epoch[3/10], Step [10/30], Loss: 0.2029, Accr: 87.63\n",
      "[10]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[19]\n",
      "Epoch[3/10], Step [20/30], Loss: 0.9569, Accr: 87.63\n",
      "[20]\n",
      "[21]\n",
      "[22]\n",
      "[23]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[27]\n",
      "[28]\n",
      "[29]\n",
      "Epoch[3/10], Step [30/30], Loss: 0.2592, Accr: 91.40\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "Epoch[4/10], Step [10/30], Loss: 0.0926, Accr: 92.90\n",
      "[10]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[19]\n",
      "Epoch[4/10], Step [20/30], Loss: 0.1313, Accr: 91.08\n",
      "[20]\n",
      "[21]\n",
      "[22]\n",
      "[23]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[27]\n",
      "[28]\n",
      "[29]\n",
      "Epoch[4/10], Step [30/30], Loss: 0.2644, Accr: 94.52\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "Epoch[5/10], Step [10/30], Loss: 0.2041, Accr: 93.98\n",
      "[10]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[19]\n",
      "Epoch[5/10], Step [20/30], Loss: 0.0427, Accr: 95.91\n",
      "[20]\n",
      "[21]\n",
      "[22]\n",
      "[23]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[27]\n",
      "[28]\n",
      "[29]\n",
      "Epoch[5/10], Step [30/30], Loss: 0.0627, Accr: 96.24\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "Epoch[6/10], Step [10/30], Loss: 0.0259, Accr: 95.91\n",
      "[10]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[19]\n",
      "Epoch[6/10], Step [20/30], Loss: 0.1037, Accr: 96.45\n",
      "[20]\n",
      "[21]\n",
      "[22]\n",
      "[23]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[27]\n",
      "[28]\n",
      "[29]\n",
      "Epoch[6/10], Step [30/30], Loss: 0.0246, Accr: 96.99\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "Epoch[7/10], Step [10/30], Loss: 0.0075, Accr: 96.24\n",
      "[10]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[19]\n",
      "Epoch[7/10], Step [20/30], Loss: 0.0153, Accr: 92.58\n",
      "[20]\n",
      "[21]\n",
      "[22]\n",
      "[23]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[27]\n",
      "[28]\n",
      "[29]\n",
      "Epoch[7/10], Step [30/30], Loss: 0.1023, Accr: 96.45\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "Epoch[8/10], Step [10/30], Loss: 0.0957, Accr: 96.77\n",
      "[10]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[19]\n",
      "Epoch[8/10], Step [20/30], Loss: 0.0396, Accr: 96.13\n",
      "[20]\n",
      "[21]\n",
      "[22]\n",
      "[23]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[27]\n",
      "[28]\n",
      "[29]\n",
      "Epoch[8/10], Step [30/30], Loss: 0.0080, Accr: 96.67\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "Epoch[9/10], Step [10/30], Loss: 0.0888, Accr: 96.77\n",
      "[10]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[19]\n",
      "Epoch[9/10], Step [20/30], Loss: 0.0484, Accr: 96.56\n",
      "[20]\n",
      "[21]\n",
      "[22]\n",
      "[23]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[27]\n",
      "[28]\n",
      "[29]\n",
      "Epoch[9/10], Step [30/30], Loss: 0.0562, Accr: 96.88\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "Epoch[10/10], Step [10/30], Loss: 0.0552, Accr: 96.56\n",
      "[10]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[19]\n",
      "Epoch[10/10], Step [20/30], Loss: 0.0072, Accr: 96.67\n",
      "[20]\n",
      "[21]\n",
      "[22]\n",
      "[23]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[27]\n",
      "[28]\n",
      "[29]\n",
      "Epoch[10/10], Step [30/30], Loss: 0.0579, Accr: 96.67\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "total_step = len(loaders.train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(loaders.train_loader): # batch_size만큼\n",
    "        texts = data.text.to(device) # (batch_size, length)\n",
    "        labels = data.label.to(device) # (batch_size, num_classes)\n",
    "        \n",
    "        print(\"[%d]\" %i)\n",
    "        \n",
    "        # Forward prop.\n",
    "        output = model(texts) # (batch_size, num_classes)\n",
    "        loss = loss_func(output, labels)\n",
    "        \n",
    "        # Backward prop. & optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 10 == 0:\n",
    "            print('Epoch[{}/{}], Step [{}/{}], Loss: {:.4f}, Accr: {:.2f}'\n",
    "                 .format(epoch+1, num_epochs, i+1, total_step,\n",
    "                        loss.item(),\n",
    "                        ComputeAccr(loaders.valid_loader, model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191917f9",
   "metadata": {},
   "source": [
    "# 7. 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2df72831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Test Data: 84.34\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Test Data: %.2f\" %ComputeAccr(test_loaders.train_loader, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0d3d43",
   "metadata": {},
   "source": [
    "# 8. 학습된 파라미터 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e147e76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type RNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "netname = './nets/rnn_weight_sms.pkl'\n",
    "torch.save(model, netname, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e48bce",
   "metadata": {},
   "source": [
    "# 9. 학습된 파라미터 로드\n",
    "실무에서 학습된(pretrained) 파라미터 로드 시 5, 6, 8 과정 생략한채 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f7882ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "netname = './nets/rnn_weight_sms.pkl'\n",
    "model = torch.load(netname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28d00ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Test Data: 84.34\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Test Data: %.2f\" %ComputeAccr(test_loaders.train_loader, model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
